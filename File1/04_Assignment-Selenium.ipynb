{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7042ef51",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping data from https://www.naukri.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89909b02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\praje\\anaconda3\\lib\\site-packages (4.22.0)\n",
      "Requirement already satisfied: urllib3[socks]<3,>=1.26 in c:\\users\\praje\\anaconda3\\lib\\site-packages (from selenium) (1.26.16)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\praje\\anaconda3\\lib\\site-packages (from selenium) (0.26.0)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\praje\\anaconda3\\lib\\site-packages (from selenium) (0.11.1)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\praje\\anaconda3\\lib\\site-packages (from selenium) (2023.7.22)\n",
      "Requirement already satisfied: typing_extensions>=4.9.0 in c:\\users\\praje\\anaconda3\\lib\\site-packages (from selenium) (4.12.2)\n",
      "Requirement already satisfied: websocket-client>=1.8.0 in c:\\users\\praje\\anaconda3\\lib\\site-packages (from selenium) (1.8.0)\n",
      "Requirement already satisfied: attrs>=23.2.0 in c:\\users\\praje\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (23.2.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\praje\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in c:\\users\\praje\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (3.4)\n",
      "Requirement already satisfied: outcome in c:\\users\\praje\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.3.0.post0)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in c:\\users\\praje\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.3.1)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\praje\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.15.1)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\praje\\anaconda3\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\praje\\anaconda3\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\praje\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\praje\\anaconda3\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9906d95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0a6146b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Answer-01:\n",
    "#scrapping the first 10 data as 1.) Job title, 2.) Job location, 3.) Company name, 4.) experience required\n",
    "\n",
    "driver01 = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "55a0bdfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#requesting to get the webpage\n",
    "driver01.get(\"https://www.naukri.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9607fe05",
   "metadata": {},
   "outputs": [],
   "source": [
    "#entering the designation\n",
    "designation01 = driver01.find_element(By.CLASS_NAME, \"suggestor-input \")\n",
    "designation01.send_keys(\"Data Scientist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6b8f9d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clicking search for the entered designation\n",
    "search01 = driver01.find_element(By.CLASS_NAME, \"qsbSubmit\")\n",
    "search01.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "70212028",
   "metadata": {},
   "outputs": [],
   "source": [
    "#filtering location wise\n",
    "locationfilter01 = driver01.find_element(By.XPATH, \"/html/body/div/div/main/div[1]/div[1]/div/div/div[2]/div[4]/div[2]/div[3]/label/i\")\n",
    "locationfilter01.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "af6eaf6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#filtering salary wise\n",
    "salaryfilter01 = driver01.find_element(By.XPATH, \"/html/body/div/div/main/div[1]/div[1]/div/div/div[2]/div[5]/div[2]/div[2]/label/i\")\n",
    "salaryfilter01.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ec73e246",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scarpping the given details for the first 10 itmes\n",
    "\n",
    "job_title = []\n",
    "job_location = []\n",
    "company_name = []\n",
    "experience_required = []\n",
    "\n",
    "#scrapping the titles from the given page\n",
    "title_tags01 = driver01.find_elements(By.XPATH, '//div[@class=\"cust-job-tuple layout-wrapper lay-2 sjw__tuple \"]/div/a')\n",
    "for i in title_tags01[0:10]:\n",
    "    title01=i.text\n",
    "    job_title.append(title01)\n",
    "    \n",
    "#scrapping the locations from the given page\n",
    "location_tags01 = driver01.find_elements(By.XPATH, '//span[@class=\"ni-job-tuple-icon ni-job-tuple-icon-srp-location loc\"]')\n",
    "for i in location_tags01[0:10]:\n",
    "    location01 = i.text\n",
    "    job_location.append(location01)\n",
    "    \n",
    "#scrapping company name from given page\n",
    "company_tags01 = driver01.find_elements(By.XPATH, '//div[@class=\" row2\"]/span/a[1]')\n",
    "for i in company_tags01[0:10]:\n",
    "    company01 = i.text\n",
    "    company_name.append(company01)\n",
    "    \n",
    "#scrapping required experience from the given page\n",
    "experience_tags01 = driver01.find_elements(By.XPATH, '//span[@class=\"expwdth\"]')\n",
    "for i in experience_tags01[0:10]:\n",
    "    experience01 = i.text\n",
    "    experience_required.append(experience01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e53b9177",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10\n"
     ]
    }
   ],
   "source": [
    "print(len(job_title), len(job_location), len(company_name), len(experience_required))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c6e6a843",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Experience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Delhi / NCR, Pune, Bengaluru</td>\n",
       "      <td>Wipro</td>\n",
       "      <td>6-11 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist III</td>\n",
       "      <td>Gurugram</td>\n",
       "      <td>Flutter</td>\n",
       "      <td>2-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>Sociomix</td>\n",
       "      <td>0-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data scientist</td>\n",
       "      <td>Gurugram</td>\n",
       "      <td>Growthjockey</td>\n",
       "      <td>0-1 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Kolkata, Mumbai, New Delhi, Hyderabad, Pune, C...</td>\n",
       "      <td>Essenware</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist (Telco)</td>\n",
       "      <td>Gurugram, Bengaluru</td>\n",
       "      <td>PayU</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Gurugram</td>\n",
       "      <td>Orange Business Services</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Noida</td>\n",
       "      <td>Ericsson</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Noida</td>\n",
       "      <td>Times Internet</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Noida</td>\n",
       "      <td>Ericsson</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Title                                           Location  \\\n",
       "0          Data Scientist                       Delhi / NCR, Pune, Bengaluru   \n",
       "1      Data Scientist III                                           Gurugram   \n",
       "2          Data Scientist                                          New Delhi   \n",
       "3          Data scientist                                           Gurugram   \n",
       "4          Data Scientist  Kolkata, Mumbai, New Delhi, Hyderabad, Pune, C...   \n",
       "5  Data Scientist (Telco)                                Gurugram, Bengaluru   \n",
       "6          Data Scientist                                           Gurugram   \n",
       "7          Data Scientist                                              Noida   \n",
       "8          Data Scientist                                              Noida   \n",
       "9          Data Scientist                                              Noida   \n",
       "\n",
       "               Company Name Experience  \n",
       "0                     Wipro   6-11 Yrs  \n",
       "1                   Flutter    2-6 Yrs  \n",
       "2                  Sociomix    0-5 Yrs  \n",
       "3              Growthjockey    0-1 Yrs  \n",
       "4                 Essenware    2-5 Yrs  \n",
       "5                      PayU    2-7 Yrs  \n",
       "6  Orange Business Services    3-5 Yrs  \n",
       "7                  Ericsson    3-7 Yrs  \n",
       "8            Times Internet    3-8 Yrs  \n",
       "9                  Ericsson    3-7 Yrs  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({'Title': job_title, 'Location':job_location, 'Company Name': company_name, 'Experience':experience_required})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "50e24245",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Answer-02\n",
    "#scrapping the first 10 data as 1.) Job title, 2.) Job location, 3.) Company name, 4.) experience required\n",
    "driver02 = webdriver.Chrome()\n",
    "driver02.get(\"https://www.shine.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6f48f320",
   "metadata": {},
   "outputs": [],
   "source": [
    "#entering designation as per required in the question\n",
    "\n",
    "designation02 = driver02.find_element(By.CLASS_NAME, \"form-control  \")\n",
    "designation02.send_keys(\"Data Analyst\")\n",
    "\n",
    "#entering location as per required in the question\n",
    "location02 = driver02.find_element(By.XPATH, \"/html/body/div/div[4]/div/div[2]/div[2]/div/form/div/div[1]/ul/li[2]/div/input\")\n",
    "location02.send_keys(\"Bangalore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "44ac7ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clciking on search button\n",
    "\n",
    "search02 = driver02.find_element(By.CLASS_NAME, \"searchForm_btnWrap_advance__VYBHN\")\n",
    "search02.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fe01c4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scarpping the given details for the first 10 itmes\n",
    "\n",
    "job_title = []\n",
    "job_location = []\n",
    "company_name = []\n",
    "experience_required = []\n",
    "\n",
    "#scrapping the titles from the given page\n",
    "title_tags02 = driver02.find_elements(By.XPATH, '//strong[@class=\"jobCard_pReplaceH2__xWmHg\"]/p/a')\n",
    "for i in title_tags02[0:10]:\n",
    "    title02=i.text\n",
    "    job_title.append(title02)\n",
    "    \n",
    "#scrapping the locations from the given page\n",
    "location_tags02 = driver02.find_elements(By.XPATH, '//div[@class=\"jobCard_jobCard_lists_item__YxRkV jobCard_locationIcon__zrWt2\"]')\n",
    "for i in location_tags02[0:10]:\n",
    "    location02 = i.text\n",
    "    job_location.append(location02)\n",
    "    \n",
    "#scrapping company name from given page\n",
    "company_tags02 = driver02.find_elements(By.XPATH, '//div[@class=\"jobCard_jobCard_cName__mYnow\"]')\n",
    "for i in company_tags02[0:10]:\n",
    "    company02 = i.text\n",
    "    company_name.append(company02)\n",
    "    \n",
    "#scrapping required experience from the given page\n",
    "experience_tags02 = driver02.find_elements(By.XPATH, '//div[@class=\" jobCard_jobCard_lists_item__YxRkV jobCard_jobIcon__3FB1t\"]')\n",
    "for i in experience_tags02[0:10]:\n",
    "    experience02 = i.text\n",
    "    experience_required.append(experience02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "dea06806",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Experience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Analyst , Senior Data Analyst , Data Anal...</td>\n",
       "      <td>Bangalore\\n+8</td>\n",
       "      <td>appsoft solutions</td>\n",
       "      <td>0 to 4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore\\n+4</td>\n",
       "      <td>aryan technology</td>\n",
       "      <td>0 to 4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hr Data Analyst</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>leverage business solutions private...</td>\n",
       "      <td>4 to 8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>phoenix global re settlement servic...</td>\n",
       "      <td>3 to 8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>subhadra jobs consultancy hiring fo...</td>\n",
       "      <td>2 to 7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>subhadra jobs consultancy hiring fo...</td>\n",
       "      <td>2 to 7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Clinical Data Analyst</td>\n",
       "      <td>Bangalore\\n+6</td>\n",
       "      <td>techno endura</td>\n",
       "      <td>0 to 1 Yr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>ltimindtree limited</td>\n",
       "      <td>5 to 10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore\\n+18</td>\n",
       "      <td>neo impex stainless private limited</td>\n",
       "      <td>9 to 14 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Lead Data Analyst</td>\n",
       "      <td>Bangalore\\n+8</td>\n",
       "      <td>mackenzie modern it solutions priva...</td>\n",
       "      <td>5 to 9 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title        Location  \\\n",
       "0  Data Analyst , Senior Data Analyst , Data Anal...   Bangalore\\n+8   \n",
       "1                                       Data Analyst   Bangalore\\n+4   \n",
       "2                                    Hr Data Analyst       Bangalore   \n",
       "3                                       Data Analyst       Bangalore   \n",
       "4                                       Data Analyst       Bangalore   \n",
       "5                                       Data Analyst       Bangalore   \n",
       "6                              Clinical Data Analyst   Bangalore\\n+6   \n",
       "7                                       Data Analyst       Bangalore   \n",
       "8                                       Data Analyst  Bangalore\\n+18   \n",
       "9                                  Lead Data Analyst   Bangalore\\n+8   \n",
       "\n",
       "                             Company Name   Experience  \n",
       "0                       appsoft solutions   0 to 4 Yrs  \n",
       "1                        aryan technology   0 to 4 Yrs  \n",
       "2  leverage business solutions private...   4 to 8 Yrs  \n",
       "3  phoenix global re settlement servic...   3 to 8 Yrs  \n",
       "4  subhadra jobs consultancy hiring fo...   2 to 7 Yrs  \n",
       "5  subhadra jobs consultancy hiring fo...   2 to 7 Yrs  \n",
       "6                           techno endura    0 to 1 Yr  \n",
       "7                     ltimindtree limited  5 to 10 Yrs  \n",
       "8     neo impex stainless private limited  9 to 14 Yrs  \n",
       "9  mackenzie modern it solutions priva...   5 to 9 Yrs  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({'Title': job_title, 'Location':job_location, 'Company Name': company_name, 'Experience':experience_required})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bbec4852",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Asnswer-03:\n",
    "#Scrapping the 100 reviews from the flipkart.com for iphone11 phone\n",
    "\n",
    "driver03 = webdriver.Chrome()\n",
    "driver03.get(\"https://www.flipkart.com/apple-iphone-11-white-128-gb/product-reviews/itme32df47ea6742?pid=MOBFWQ6B7KKRXDDS&lid=LSTMOBFWQ6B7KKRXDDSULUZ0N&marketplace=FLIPKART\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1e7d182c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#scrapping the first 10 webpages for 100 reviews details\n",
    "\n",
    "rating03 = []\n",
    "review_summary03 = []\n",
    "full_review03 = []\n",
    "\n",
    "\n",
    "for page in range(0,10): #for looping for the particular page\n",
    "    ratings = driver03.find_elements(By.XPATH, '//div[@class=\"XQDdHH Ga3i8K\"]') #scrapping the ratings from given page\n",
    "    for i in ratings:\n",
    "        rating03.append(i.text)\n",
    "    review_summaries = driver03.find_elements(By.XPATH, '//p[@class=\"z9E0IG\"]') #scrapping the review summary from given page\n",
    "    for i in review_summaries:\n",
    "        review_summary03.append(i.text)\n",
    "    full_reviews = driver03.find_elements(By.XPATH, '//div[@class=\"ZmyHeo\"]') #scrapping the full review from given page\n",
    "    for i in full_reviews:\n",
    "        full_review03.append(i.text)\n",
    "        \n",
    "    next_button03 = driver03.find_element(By.XPATH, '//nav[@class=\"WSL9JP\"]/a[12]/span') #To scrap data from next poge\n",
    "    next_button03.click()\n",
    "    time.sleep(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "52cfb62d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Review Summary</th>\n",
       "      <th>Full review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Fabulous!</td>\n",
       "      <td>Superüî• and good performance üëå‚ù§Ô∏è</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>V Good all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Super!</td>\n",
       "      <td>Good product üëåI love iPhone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Awesome</td>\n",
       "      <td>iPhone 11 is a good phone. Not a very big diff...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Highly recommended</td>\n",
       "      <td>Awesome Battery Life...Camera clarity is too g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>5</td>\n",
       "      <td>Terrific purchase</td>\n",
       "      <td>Awesom Product.. Very good Experience</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Iphone is just awesome.. battery backup is ver...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>4</td>\n",
       "      <td>Pretty good</td>\n",
       "      <td>Gud one</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>5</td>\n",
       "      <td>Great product</td>\n",
       "      <td>Very good mobile... excellent camera and very ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>4</td>\n",
       "      <td>Wonderful</td>\n",
       "      <td>Good product got how i was excepted\\nValue for...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>95 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Ratings      Review Summary  \\\n",
       "0        5           Fabulous!   \n",
       "1        5    Perfect product!   \n",
       "2        5              Super!   \n",
       "3        5             Awesome   \n",
       "4        5  Highly recommended   \n",
       "..     ...                 ...   \n",
       "90       5   Terrific purchase   \n",
       "91       5    Perfect product!   \n",
       "92       4         Pretty good   \n",
       "93       5       Great product   \n",
       "94       4           Wonderful   \n",
       "\n",
       "                                          Full review  \n",
       "0                     Superüî• and good performance üëå‚ù§Ô∏è  \n",
       "1                                          V Good all  \n",
       "2                         Good product üëåI love iPhone  \n",
       "3   iPhone 11 is a good phone. Not a very big diff...  \n",
       "4   Awesome Battery Life...Camera clarity is too g...  \n",
       "..                                                ...  \n",
       "90              Awesom Product.. Very good Experience  \n",
       "91  Iphone is just awesome.. battery backup is ver...  \n",
       "92                                            Gud one  \n",
       "93  Very good mobile... excellent camera and very ...  \n",
       "94  Good product got how i was excepted\\nValue for...  \n",
       "\n",
       "[95 rows x 3 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({'Ratings': rating03[0:100], 'Review Summary':review_summary03[0:100], 'Full review': full_review03[0:100]})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "4fb84416",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Answer-04:\n",
    "#Scrapping the details from the flipkart.com for 100 items\n",
    "\n",
    "driver04 = webdriver.Chrome()\n",
    "driver04.get(\"https://www.flipkart.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "df1fdf49",
   "metadata": {},
   "outputs": [],
   "source": [
    "#entering search keyword \"sneakers\" as per required in the question\n",
    "\n",
    "search_item04 = driver04.find_element(By.CLASS_NAME, \"Pke_EE\")\n",
    "search_item04.send_keys(\"Sneakers\")\n",
    "\n",
    "click04 = driver04.find_element(By.CLASS_NAME, '_2iLD__')\n",
    "click04.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "9a09895c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#scrapping the details for 100 items\n",
    "\n",
    "brand04 = []\n",
    "product_description04 = []\n",
    "price04 = []\n",
    "\n",
    "\n",
    "for page in range(0,3): #'for' looping for the particular page\n",
    "    brands = driver04.find_elements(By.XPATH, '//div[@class=\"syl9yP\"]') #scrapping the brand name from given page\n",
    "    for i in brands:\n",
    "        brand04.append(i.text)\n",
    "    product_details = driver04.find_elements(By.XPATH, '//div[@class=\"hCKiGj\"]/a[1]') #scrapping the product description from given page\n",
    "    for i in product_details:\n",
    "        product_description04.append(i.text)\n",
    "    prices = driver04.find_elements(By.XPATH, '//div[@class=\"Nx9bqj\"]') #scrapping the prices from given page\n",
    "    for i in prices:\n",
    "        price04.append(i.text)\n",
    "        \n",
    "    next_button04 = driver04.find_element(By.XPATH, '//nav[@class=\"WSL9JP\"]/a[12]/span') #To scrap data from next poge\n",
    "    next_button04.click()\n",
    "    time.sleep(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "5355ba28",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand Name</th>\n",
       "      <th>Product Description</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BRUTON</td>\n",
       "      <td>Lattest Sneakers Shoe Sneakers For Men</td>\n",
       "      <td>‚Çπ297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Aeonik</td>\n",
       "      <td>OGIY RETRO SHOES HIGH PREMIUM QUALITY Sneakers...</td>\n",
       "      <td>‚Çπ497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RapidBox</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>‚Çπ795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ATOM</td>\n",
       "      <td>Spring Edge Alpha 2 Sneakers For Men</td>\n",
       "      <td>‚Çπ1,139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Red Tape</td>\n",
       "      <td>Sneaker Casual Shoes for Men | Soft Cushioned ...</td>\n",
       "      <td>‚Çπ1,029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>HIGHLANDER</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>‚Çπ559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>ATOM</td>\n",
       "      <td>Street Swagger Sneakers For Men</td>\n",
       "      <td>‚Çπ1,485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>PUMA</td>\n",
       "      <td>Future Rider Double Sneakers For Men</td>\n",
       "      <td>‚Çπ2,880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>HRX by Hrithik Roshan</td>\n",
       "      <td>URBAN CHUNKY Sneakers For Men</td>\n",
       "      <td>‚Çπ879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>PUMA</td>\n",
       "      <td>ST Runner v3 L Sneakers For Men</td>\n",
       "      <td>‚Çπ2,150</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Brand Name                                Product Description  \\\n",
       "0                  BRUTON             Lattest Sneakers Shoe Sneakers For Men   \n",
       "1                  Aeonik  OGIY RETRO SHOES HIGH PREMIUM QUALITY Sneakers...   \n",
       "2                RapidBox                                   Sneakers For Men   \n",
       "3                    ATOM               Spring Edge Alpha 2 Sneakers For Men   \n",
       "4                Red Tape  Sneaker Casual Shoes for Men | Soft Cushioned ...   \n",
       "..                    ...                                                ...   \n",
       "95             HIGHLANDER                                   Sneakers For Men   \n",
       "96                   ATOM                    Street Swagger Sneakers For Men   \n",
       "97                   PUMA               Future Rider Double Sneakers For Men   \n",
       "98  HRX by Hrithik Roshan                      URBAN CHUNKY Sneakers For Men   \n",
       "99                   PUMA                    ST Runner v3 L Sneakers For Men   \n",
       "\n",
       "     Price  \n",
       "0     ‚Çπ297  \n",
       "1     ‚Çπ497  \n",
       "2     ‚Çπ795  \n",
       "3   ‚Çπ1,139  \n",
       "4   ‚Çπ1,029  \n",
       "..     ...  \n",
       "95    ‚Çπ559  \n",
       "96  ‚Çπ1,485  \n",
       "97  ‚Çπ2,880  \n",
       "98    ‚Çπ879  \n",
       "99  ‚Çπ2,150  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({'Brand Name':brand04[0:100], 'Product Description':product_description04[0:100], 'Price':price04[0:100]})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "f87d5bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Answer-05:\n",
    "#Scrapping the 100 reviews from the amazon.com for Laptop phone\n",
    "\n",
    "driver05 = webdriver.Chrome()\n",
    "driver05.get(\" https://www.amazon.in/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "1eb0c6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#entering search keyword \"Laptop\" as per required in the question\n",
    "\n",
    "search_item05 = driver05.find_element(By.XPATH, '//div[@class=\"nav-search-field \"]/input')\n",
    "search_item05.send_keys(\"Laptop\")\n",
    "\n",
    "click05 = driver05.find_element(By.XPATH, '//span[@class=\"nav-search-submit-text nav-sprite nav-progressive-attribute\"]/input')\n",
    "click05.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "133d7338",
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter with cpu type as intel core i7\n",
    "filtering_cpu_type = driver05.find_element(By.XPATH, '//li[@id=\"p_n_feature_thirteen_browse-bin/12598163031\"]/span/a/div/label/i')\n",
    "filtering_cpu_type.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "a936c433",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scrapping the first 10 items\n",
    "\n",
    "title = []\n",
    "rating = []\n",
    "price = []\n",
    "\n",
    "    \n",
    "titles05 = driver05.find_elements(By.XPATH, '//span[@class=\"a-size-medium a-color-base a-text-normal\"]') #scrapping the title name from given page\n",
    "for i in titles05[0:10]:\n",
    "    title.append(i.text)\n",
    "rating05 = driver05.find_elements(By.XPATH, '//span[@class=\"a-size-base s-underline-text\"]') #scrapping the ratings from given page\n",
    "for i in rating05[0:10]:\n",
    "    rating.append(i.text)\n",
    "price05 = driver05.find_elements(By.XPATH, '//span[@class=\"a-price\"]/span/span[2]') #scrapping the prices from given page\n",
    "for i in price05[0:10]:\n",
    "    price.append(i.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "cac5614b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10\n"
     ]
    }
   ],
   "source": [
    "print(len(title), len(rating), len(price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "635cf9c8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['131', '63', '337', '44', '270', '22', '122', '686', '106', '39']\n"
     ]
    }
   ],
   "source": [
    "print(rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "af2fce1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Item Title</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MSI Modern 14, Intel 12th Gen. i7-1255U, 36CM ...</td>\n",
       "      <td>131</td>\n",
       "      <td>47,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HP Laptop 15s, 12th Gen Intel Core i7-1255U, 1...</td>\n",
       "      <td>63</td>\n",
       "      <td>65,490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lenovo IdeaPad 3 Intel Core i7 12th Gen 1255U ...</td>\n",
       "      <td>337</td>\n",
       "      <td>62,009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bestor 4-Port USB 3.0 Hub [90¬∞/180¬∞ Degree Rot...</td>\n",
       "      <td>44</td>\n",
       "      <td>599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ASUS Vivobook 15, Intel Core i7-12650H 12th Ge...</td>\n",
       "      <td>270</td>\n",
       "      <td>64,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Lenovo IdeaPad Slim 5 Intel Core i7 13700H 16\"...</td>\n",
       "      <td>22</td>\n",
       "      <td>84,190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>HP Pavilion 14 12th Gen Intel Core i7 16GB SDR...</td>\n",
       "      <td>122</td>\n",
       "      <td>78,850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Dell Latitude 7480 14in FHD Laptop PC - Intel ...</td>\n",
       "      <td>686</td>\n",
       "      <td>80,490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Dell [Smartchoice Inspiron 5430 Thin &amp; Light L...</td>\n",
       "      <td>106</td>\n",
       "      <td>83,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>HP Pavilion 15, 13th Gen Intel Core i7-1360P, ...</td>\n",
       "      <td>39</td>\n",
       "      <td>88,990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Item Title Ratings   Price\n",
       "0  MSI Modern 14, Intel 12th Gen. i7-1255U, 36CM ...     131  47,990\n",
       "1  HP Laptop 15s, 12th Gen Intel Core i7-1255U, 1...      63  65,490\n",
       "2  Lenovo IdeaPad 3 Intel Core i7 12th Gen 1255U ...     337  62,009\n",
       "3  Bestor 4-Port USB 3.0 Hub [90¬∞/180¬∞ Degree Rot...      44     599\n",
       "4  ASUS Vivobook 15, Intel Core i7-12650H 12th Ge...     270  64,990\n",
       "5  Lenovo IdeaPad Slim 5 Intel Core i7 13700H 16\"...      22  84,190\n",
       "6  HP Pavilion 14 12th Gen Intel Core i7 16GB SDR...     122  78,850\n",
       "7  Dell Latitude 7480 14in FHD Laptop PC - Intel ...     686  80,490\n",
       "8  Dell [Smartchoice Inspiron 5430 Thin & Light L...     106  83,990\n",
       "9  HP Pavilion 15, 13th Gen Intel Core i7-1360P, ...      39  88,990"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({'Item Title':title, 'Ratings':rating, 'Price':price})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "87bf6cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Answer-06:\n",
    "#scrapping the top 1000 quotes of all time from https://www.azquotes.com/ \n",
    "\n",
    "driver06 = webdriver.Chrome()\n",
    "driver06.get(\"https://www.azquotes.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "1b021753",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clicking on top quotes\n",
    "\n",
    "click06 = driver06.find_element(By.XPATH, '//div[@class=\"mainmenu\"]/ul/li[5]/a')\n",
    "click06.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "0b016b24",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NoSuchElementException",
     "evalue": "Message: no such element: Unable to locate element: {\"method\":\"xpath\",\"selector\":\"//li[@class=\"next\"][1]\"}\n  (Session info: chrome=126.0.6478.127); For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#no-such-element-exception\nStacktrace:\n\tGetHandleVerifier [0x00007FF60678EEA2+31554]\n\t(No symbol) [0x00007FF606707ED9]\n\t(No symbol) [0x00007FF6065C872A]\n\t(No symbol) [0x00007FF606618434]\n\t(No symbol) [0x00007FF60661853C]\n\t(No symbol) [0x00007FF60665F6A7]\n\t(No symbol) [0x00007FF60663D06F]\n\t(No symbol) [0x00007FF60665C977]\n\t(No symbol) [0x00007FF60663CDD3]\n\t(No symbol) [0x00007FF60660A33B]\n\t(No symbol) [0x00007FF60660AED1]\n\tGetHandleVerifier [0x00007FF606A98B1D+3217341]\n\tGetHandleVerifier [0x00007FF606AE5AE3+3532675]\n\tGetHandleVerifier [0x00007FF606ADB0E0+3489152]\n\tGetHandleVerifier [0x00007FF60683E776+750614]\n\t(No symbol) [0x00007FF60671375F]\n\t(No symbol) [0x00007FF60670EB14]\n\t(No symbol) [0x00007FF60670ECA2]\n\t(No symbol) [0x00007FF6066FE16F]\n\tBaseThreadInitThunk [0x00007FFB610F7344+20]\n\tRtlUserThreadStart [0x00007FFB6303CC91+33]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNoSuchElementException\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[204], line 18\u001b[0m\n\u001b[0;32m     15\u001b[0m     list_i\u001b[38;5;241m.\u001b[39mappend(i\u001b[38;5;241m.\u001b[39mtext)\n\u001b[0;32m     16\u001b[0m     quote_type\u001b[38;5;241m.\u001b[39mappend(list_i)\n\u001b[1;32m---> 18\u001b[0m next_button06 \u001b[38;5;241m=\u001b[39m driver06\u001b[38;5;241m.\u001b[39mfind_element(By\u001b[38;5;241m.\u001b[39mXPATH, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m//li[@class=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnext\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m][1]\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;66;03m#To scrap data from next poge\u001b[39;00m\n\u001b[0;32m     19\u001b[0m next_button06\u001b[38;5;241m.\u001b[39mclick()\n\u001b[0;32m     20\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:748\u001b[0m, in \u001b[0;36mWebDriver.find_element\u001b[1;34m(self, by, value)\u001b[0m\n\u001b[0;32m    745\u001b[0m     by \u001b[38;5;241m=\u001b[39m By\u001b[38;5;241m.\u001b[39mCSS_SELECTOR\n\u001b[0;32m    746\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[name=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m--> 748\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecute(Command\u001b[38;5;241m.\u001b[39mFIND_ELEMENT, {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124musing\u001b[39m\u001b[38;5;124m\"\u001b[39m: by, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m: value})[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:354\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    352\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_executor\u001b[38;5;241m.\u001b[39mexecute(driver_command, params)\n\u001b[0;32m    353\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[1;32m--> 354\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merror_handler\u001b[38;5;241m.\u001b[39mcheck_response(response)\n\u001b[0;32m    355\u001b[0m     response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unwrap_value(response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    356\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py:229\u001b[0m, in \u001b[0;36mErrorHandler.check_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    227\u001b[0m         alert_text \u001b[38;5;241m=\u001b[39m value[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malert\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    228\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace, alert_text)  \u001b[38;5;66;03m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[39;00m\n\u001b[1;32m--> 229\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace)\n",
      "\u001b[1;31mNoSuchElementException\u001b[0m: Message: no such element: Unable to locate element: {\"method\":\"xpath\",\"selector\":\"//li[@class=\"next\"][1]\"}\n  (Session info: chrome=126.0.6478.127); For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#no-such-element-exception\nStacktrace:\n\tGetHandleVerifier [0x00007FF60678EEA2+31554]\n\t(No symbol) [0x00007FF606707ED9]\n\t(No symbol) [0x00007FF6065C872A]\n\t(No symbol) [0x00007FF606618434]\n\t(No symbol) [0x00007FF60661853C]\n\t(No symbol) [0x00007FF60665F6A7]\n\t(No symbol) [0x00007FF60663D06F]\n\t(No symbol) [0x00007FF60665C977]\n\t(No symbol) [0x00007FF60663CDD3]\n\t(No symbol) [0x00007FF60660A33B]\n\t(No symbol) [0x00007FF60660AED1]\n\tGetHandleVerifier [0x00007FF606A98B1D+3217341]\n\tGetHandleVerifier [0x00007FF606AE5AE3+3532675]\n\tGetHandleVerifier [0x00007FF606ADB0E0+3489152]\n\tGetHandleVerifier [0x00007FF60683E776+750614]\n\t(No symbol) [0x00007FF60671375F]\n\t(No symbol) [0x00007FF60670EB14]\n\t(No symbol) [0x00007FF60670ECA2]\n\t(No symbol) [0x00007FF6066FE16F]\n\tBaseThreadInitThunk [0x00007FFB610F7344+20]\n\tRtlUserThreadStart [0x00007FFB6303CC91+33]\n"
     ]
    }
   ],
   "source": [
    "quote = []\n",
    "author = []\n",
    "quote_type = []\n",
    "\n",
    "for page in range(0,10): #'for' looping for the particular page\n",
    "    quotes = driver06.find_elements(By.XPATH, '//ul[@class=\"list-quotes\"]/li/div/p/a[2]') #scrapping the quotes from given page\n",
    "    for i in quotes:\n",
    "        quote.append(i.text)\n",
    "    authors = driver06.find_elements(By.XPATH, '//ul[@class=\"list-quotes\"]/li/div/div/a') #scrapping the authors from given page\n",
    "    for i in authors:\n",
    "        author.append(i.text)\n",
    "    quote_types = driver06.find_elements(By.XPATH, '//ul[@class=\"list-quotes\"]/li/div/div[2]') #scrapping the type of quotes from given page\n",
    "    for i in quote_types:\n",
    "        list_i = []\n",
    "        list_i.append(i.text)\n",
    "        quote_type.append(list_i)\n",
    "        \n",
    "    next_button06 = driver06.find_element(By.XPATH, '//li[@class=\"next\"][1]') #To scrap data from next poge\n",
    "    next_button06.click()\n",
    "    time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "83f2bfda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 1000 100\n"
     ]
    }
   ],
   "source": [
    "print(len(quote), len(author), len(quote_types))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "b810f165",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Quote</th>\n",
       "      <th>Author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The essence of strategy is choosing what not t...</td>\n",
       "      <td>Michael Porter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>One cannot and must not try to erase the past ...</td>\n",
       "      <td>Golda Meir</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Patriotism means to stand by the country. It d...</td>\n",
       "      <td>Theodore Roosevelt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Death is something inevitable. When a man has ...</td>\n",
       "      <td>Nelson Mandela</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You have to love a nation that celebrates its ...</td>\n",
       "      <td>Erma Bombeck</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>Regret for the things we did can be tempered b...</td>\n",
       "      <td>Sydney J. Harris</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>America... just a nation of two hundred millio...</td>\n",
       "      <td>Hunter S. Thompson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>For every disciplined effort there is a multip...</td>\n",
       "      <td>Jim Rohn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>The spiritual journey is individual, highly pe...</td>\n",
       "      <td>Ram Dass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>The mind is not a vessel to be filled but a fi...</td>\n",
       "      <td>Plutarch</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Quote              Author\n",
       "0    The essence of strategy is choosing what not t...      Michael Porter\n",
       "1    One cannot and must not try to erase the past ...          Golda Meir\n",
       "2    Patriotism means to stand by the country. It d...  Theodore Roosevelt\n",
       "3    Death is something inevitable. When a man has ...      Nelson Mandela\n",
       "4    You have to love a nation that celebrates its ...        Erma Bombeck\n",
       "..                                                 ...                 ...\n",
       "995  Regret for the things we did can be tempered b...    Sydney J. Harris\n",
       "996  America... just a nation of two hundred millio...  Hunter S. Thompson\n",
       "997  For every disciplined effort there is a multip...            Jim Rohn\n",
       "998  The spiritual journey is individual, highly pe...            Ram Dass\n",
       "999  The mind is not a vessel to be filled but a fi...            Plutarch\n",
       "\n",
       "[1000 rows x 2 columns]"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({'Quote':quote[0:1000], 'Author':author[0:1000]})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2e3f54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Answer-07:\n",
    "#scrapping the details of respected former prime ministers of india\n",
    "\n",
    "driver07 = webdriver.Chrome()\n",
    "driver07.get(\"https://www.jagranjosh.com/general-knowledge/list-ofall-prime-ministers-of-india-1473165149-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a395905",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#scarpping the details of respected former prime ministers\n",
    "\n",
    "name = []\n",
    "born_dead = []\n",
    "office_term = []\n",
    "remarks = []\n",
    "\n",
    "#scrapping the Names from the given page\n",
    "names = driver07.find_elements(By.XPATH, '//div[@class=\"TableData\"]/table/tbody/tr/td[2]/div')\n",
    "for i in names:\n",
    "    names07=i.text\n",
    "    name.append(names07)\n",
    "    \n",
    "#scrapping the Born-dead from the given page\n",
    "born_deads = driver07.find_elements(By.XPATH, '//div[@class=\"TableData\"]/table/tbody/tr/td[3]/div')\n",
    "for i in born_deads:\n",
    "    born_deads07 = i.text\n",
    "    born_dead.append(born_deads07)\n",
    "    \n",
    "#scrapping office term from given page\n",
    "term_of_office = driver07.find_elements(By.XPATH, '//div[@class=\"TableData\"]/table/tbody/tr/td[4]')\n",
    "for i in term_of_office:\n",
    "    office_term07 = i.text\n",
    "    office_term.append(office_term07)\n",
    "\n",
    "    #scrapping remarks from the given page\n",
    "remarks = driver07.find_elements(By.XPATH, '//div[@class=\"TableData\"]/table/tbody/tr/td[5]')\n",
    "for i in remarks:\n",
    "    remark07 = i.text\n",
    "    remarks.append(remark07)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c81654d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({'Names':name, 'Born-Dead':born_dead}, 'Term of office':office_term, 'Remarks':remarks)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5cf1e16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Answer-08\n",
    "#scrapping the list of 50 most expensive cars in the world\n",
    "\n",
    "driver08 = webdriver.Chrome()\n",
    "driver08.get(\"https://www.motor1.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "111f3731",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ElementNotInteractableException",
     "evalue": "Message: element not interactable\n  (Session info: chrome=126.0.6478.127)\nStacktrace:\n\tGetHandleVerifier [0x00007FF7361EEEA2+31554]\n\t(No symbol) [0x00007FF736167ED9]\n\t(No symbol) [0x00007FF736028559]\n\t(No symbol) [0x00007FF736071D73]\n\t(No symbol) [0x00007FF73606FEDB]\n\t(No symbol) [0x00007FF73609D02A]\n\t(No symbol) [0x00007FF73606BA76]\n\t(No symbol) [0x00007FF73609D240]\n\t(No symbol) [0x00007FF7360BC977]\n\t(No symbol) [0x00007FF73609CDD3]\n\t(No symbol) [0x00007FF73606A33B]\n\t(No symbol) [0x00007FF73606AED1]\n\tGetHandleVerifier [0x00007FF7364F8B1D+3217341]\n\tGetHandleVerifier [0x00007FF736545AE3+3532675]\n\tGetHandleVerifier [0x00007FF73653B0E0+3489152]\n\tGetHandleVerifier [0x00007FF73629E776+750614]\n\t(No symbol) [0x00007FF73617375F]\n\t(No symbol) [0x00007FF73616EB14]\n\t(No symbol) [0x00007FF73616ECA2]\n\t(No symbol) [0x00007FF73615E16F]\n\tBaseThreadInitThunk [0x00007FFCE0DE7344+20]\n\tRtlUserThreadStart [0x00007FFCE103CC91+33]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mElementNotInteractableException\u001b[0m           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m search08 \u001b[38;5;241m=\u001b[39m driver08\u001b[38;5;241m.\u001b[39mfind_element(By\u001b[38;5;241m.\u001b[39mXPATH, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/html/body/div[9]/div[2]/div/div/div[3]/div/div/div/form/input\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m search08\u001b[38;5;241m.\u001b[39msend_keys(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m50 most expensive cars in the world\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\selenium\\webdriver\\remote\\webelement.py:231\u001b[0m, in \u001b[0;36mWebElement.send_keys\u001b[1;34m(self, *value)\u001b[0m\n\u001b[0;32m    228\u001b[0m             remote_files\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_upload(file))\n\u001b[0;32m    229\u001b[0m         value \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(remote_files)\n\u001b[1;32m--> 231\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_execute(\n\u001b[0;32m    232\u001b[0m     Command\u001b[38;5;241m.\u001b[39mSEND_KEYS_TO_ELEMENT, {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(keys_to_typing(value)), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m: keys_to_typing(value)}\n\u001b[0;32m    233\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\selenium\\webdriver\\remote\\webelement.py:395\u001b[0m, in \u001b[0;36mWebElement._execute\u001b[1;34m(self, command, params)\u001b[0m\n\u001b[0;32m    393\u001b[0m     params \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    394\u001b[0m params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_id\n\u001b[1;32m--> 395\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parent\u001b[38;5;241m.\u001b[39mexecute(command, params)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:354\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    352\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_executor\u001b[38;5;241m.\u001b[39mexecute(driver_command, params)\n\u001b[0;32m    353\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[1;32m--> 354\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merror_handler\u001b[38;5;241m.\u001b[39mcheck_response(response)\n\u001b[0;32m    355\u001b[0m     response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unwrap_value(response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    356\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py:229\u001b[0m, in \u001b[0;36mErrorHandler.check_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    227\u001b[0m         alert_text \u001b[38;5;241m=\u001b[39m value[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malert\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    228\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace, alert_text)  \u001b[38;5;66;03m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[39;00m\n\u001b[1;32m--> 229\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace)\n",
      "\u001b[1;31mElementNotInteractableException\u001b[0m: Message: element not interactable\n  (Session info: chrome=126.0.6478.127)\nStacktrace:\n\tGetHandleVerifier [0x00007FF7361EEEA2+31554]\n\t(No symbol) [0x00007FF736167ED9]\n\t(No symbol) [0x00007FF736028559]\n\t(No symbol) [0x00007FF736071D73]\n\t(No symbol) [0x00007FF73606FEDB]\n\t(No symbol) [0x00007FF73609D02A]\n\t(No symbol) [0x00007FF73606BA76]\n\t(No symbol) [0x00007FF73609D240]\n\t(No symbol) [0x00007FF7360BC977]\n\t(No symbol) [0x00007FF73609CDD3]\n\t(No symbol) [0x00007FF73606A33B]\n\t(No symbol) [0x00007FF73606AED1]\n\tGetHandleVerifier [0x00007FF7364F8B1D+3217341]\n\tGetHandleVerifier [0x00007FF736545AE3+3532675]\n\tGetHandleVerifier [0x00007FF73653B0E0+3489152]\n\tGetHandleVerifier [0x00007FF73629E776+750614]\n\t(No symbol) [0x00007FF73617375F]\n\t(No symbol) [0x00007FF73616EB14]\n\t(No symbol) [0x00007FF73616ECA2]\n\t(No symbol) [0x00007FF73615E16F]\n\tBaseThreadInitThunk [0x00007FFCE0DE7344+20]\n\tRtlUserThreadStart [0x00007FFCE103CC91+33]\n"
     ]
    }
   ],
   "source": [
    "#searching the keywords\n",
    "search08 = driver08.find_element(By.XPATH, '/html/body/div[9]/div[2]/div/div/div[3]/div/div/div/form/input')\n",
    "search08.send_keys(\"50 most expensive cars in the world\")\n",
    "\n",
    "#clicking the search button\n",
    "click08 = driver08.find_element(By.XPATH, '/html/body/div[9]/div[2]/div/div/div[3]/div/div/button/svg')\n",
    "click08.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c498cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scrapping car details\n",
    "car_name = []\n",
    "price = []\n",
    "\n",
    "cars = driver.find_element(By.XPATH, '//h3[@class=\"subheader\"]')\n",
    "for i in cars:\n",
    "    car08 = i.text\n",
    "    car_name.append(car08)\n",
    "prices=driver.find_element(By.XPATH, '/html/body/div[9]/div[7]/div[2]/div[1]/div[2]/div[2]/p[4]/strong')\n",
    "for i in prices:\n",
    "    price08 = i.text\n",
    "    price.append(price08)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae027a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({'Car Name':car_name, 'Price':price})\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
